
Contiguous memory management is a memory allocation technique where each process is allocated a single continuous block of memory based on the process's size. This means that a process's entire memory needs are placed in one uninterrupted section of physical memory.

**Contiguous Memory Management has two types:**
- Fixed(or Static) Partition
- Variable(or Dynamic) Partitioning

## 1. Fixed Partition (Static Partition)
Fixed partitioning is a memory management technique where the main memory is divided into fixed-sized partitions or blocks (They all may be of same size or different). Each partition can hold exactly one process. The size of the partitions is determined at the time of system initialization and remains constant throughout the system's operation. When a process is loaded into memory, it is placed in one of the partitions that is large enough to accommodate it.

#### There are various cons of using this technique.

**1. Internal Fragmentation**
If the size of the process is lesser then the total size of the partition then some size of the partition get wasted and remain unused. This is wastage of the memory and called internal fragmentation.
As shown in the image below, the 4 MB partition is used to load only 3 MB process and the remaining 1 MB got wasted.

**2. External Fragmentation**
The total unused space of various partitions cannot be used to load the processes even though there is space available but not in the contiguous form.
As shown in the image below, the remaining 1 MB space of each partition cannot be used as a unit to store a 4 MB process. Despite of the fact that the sufficient space is available to load the process, process will not be loaded.

**3. Limitation on the size of the process**
If the process size is larger than the size of maximum sized partition then that process cannot be loaded into the memory. Therefore, a limitation can be imposed on the process size that is it cannot be larger than the size of the largest partition.

**4. Degree of multiprogramming is less**
By Degree of multi programming, we simply mean the maximum number of processes that can be loaded into the memory at the same time. In fixed partitioning, the degree of multiprogramming is fixed and very less due to the fact that the size of the partition cannot be varied according to the size of processes.

![[os-fixed-partitioning.png]]

## 2. Variable Partitioning (Dynamic Partitioning)
Dynamic partitioning tries to overcome the problems caused by fixed partitioning. In this technique, **the partition size is not declared initially. It is declared at the time of process loading**.

The first partition is reserved for the operating system. The remaining space is divided into parts. **The size of each partition will be equal to the size of the process**. The partition size varies according to the need of the process so that the internal fragmentation can be avoided.

![[os-dynamic-partitioning.png]]


#### Advantages of Dynamic Partitioning over fixed partitioning

- **1. No Internal Fragmentation**
  Given the fact that the partitions in dynamic partitioning are created according to the need of the process, It is clear that there will not be any internal fragmentation because there will not be any unused remaining space in the partition.

- **2. No Limitation on the size of the process**
  In Fixed partitioning, the process with the size greater than the size of the largest partition could not be executed due to the lack of sufficient contiguous memory. Here, In Dynamic partitioning, the process size can't be restricted since the partition size is decided according to the process size.

- **3. Degree of multiprogramming is dynamic**
  The number of processes that can reside in the main memory at the same time is not fixed as it is in the Fixed Partitioning and can change based on system conditions, memory availability, and process requirements.


#### Disadvantages of dynamic partitioning

- **1.  External Fragmentation**
  Absence of internal fragmentation doesn't mean that there will not be external fragmentation.
  Let's consider three processes P1 (1 MB) and P2 (3 MB) and P3 (1 MB) are being loaded in the respective partitions of the main memory.
  After some time P1 and P3 got completed and their assigned space is freed. Now there are two unused partitions (1 MB and 1 MB) available in the main memory but they cannot be used to load a 2 MB process in the memory since they are not contiguously located.
  The rule says that the process must be contiguously present in the main memory to get executed. We need to change this rule to avoid external fragmentation.
  
![[os-dynamic-partitioning-external-fragmentation.png]]


- **2. Complex Memory Allocation**
  In Fixed partitioning, the list of partitions is made once and will never change but in dynamic partitioning, the allocation and deallocation is very complex since the partition size will be varied every time when it is assigned to a new process. OS has to keep track of all the partitions.
  Due to the fact that the allocation and deallocation are done very frequently in dynamic memory allocation and the partition size will be changed at each time, it is going to be very difficult for OS to manage everything.



### Compaction
**Compaction is a memory management technique used to reduce or eliminate external fragmentation** in systems that use dynamic memory allocation. Over time, as processes are loaded and unloaded from memory, gaps (or free spaces) appear between allocated memory blocks, leading to external fragmentation. These gaps may collectively have enough free space for a new process, but because the memory is not contiguous, it cannot be used effectively.
This technique is also called defragmentation.

##### How Compaction Works:

1. **Shuffling Processes:** Compaction involves shifting the allocated memory blocks to one end of the memory space to create a large, contiguous block of free memory at the other end.
    
2. **Rearranging Free Spaces:** The scattered free spaces between processes are consolidated into one larger block of free memory, which can then be used for new processes or tasks.
    
3. **Process Relocation:** Since processes are moved during compaction, the memory addresses that the processes were using may change. The system needs to update these addresses in the process's tables to reflect the new memory locations.


![[os-compaction.png]]

As shown in the image above, the process P5, which could not be loaded into the memory due to the lack of contiguous space, can be loaded now in the memory since the free partitions are made contiguous.


##### Problem with Compaction

The efficiency of the system is decreased in the case of compaction due to the fact that all the free spaces will be transferred from several places to a single place.

Huge amount of time is invested for this procedure and the CPU will remain idle for all this time. Despite of the fact that the compaction avoids external fragmentation, it makes system inefficient.

Let us consider that OS needs 6 NS to copy 1 byte from one place to another.

```
 1 B transfer needs 6 NS   
 256 MB transfer needs 256 X 2^20 X 6 X 10 ^ -9 secs  
```

hence, it is proved to some extent that the larger size memory transfer needs some huge amount of time that is in seconds.


### Bit Map for Dynamic Partitioning
The Main concern for dynamic partitioning is keeping track of all the free and allocated partitions. However, the Operating system uses following data structures for this task.
1. Bit Map
2. Linked List


- In **dynamic partitioning**, memory is divided into **allocation units** of fixed size, though the partition size can vary.
- The **Bit Map** is used to keep track of whether the memory is allocated or free.


1. **Bit Map Structure**:
    - Each **allocation unit** is represented by a **bit** in the bitmap.
    - **1** indicates the allocation unit is **occupied** (process present).
    - **0** indicates the allocation unit is **free** (hole in memory).
      
2. **Flag Bit**:
    - A **flag bit** is defined for each allocation unit.
    - It is set to **1** if a process is adjacent and contiguous; otherwise, it is **0**.
    - A string of `0`s represents a **hole**, while a string of `1`s represents a **process** in memory.
      (Do more research on Flag Bit)
      
3. **Memory Overhead**:
    - The **size of the bitmap** depends on the number of allocation units.
    - For example, if the allocation unit is 4 bits that is 0.5 bytes, the size of the bitmap is calculated as:
        
        `Size of bitmap = 1 / (Allocation Unit Size + 1) = 1/5 of the total main memory.`
        
    - This leads to some memory being used by the bitmap, reducing memory available for processes (in this bitmap configuration, 1/5 of total main memory is wasted).


   ![[os-bit-map-for-dynamic-partitioning.png]]


##### Disadvantages of Bit Map:
1. **Memory Overhead**:
    - The bitmap itself consumes some memory, which reduces the **degree of multiprogramming** and **throughput**.
    - In the example given, **1/5 of total memory** is wasted for storing the bitmap.
2. **Search Time**:
    - Searching for a free block (string of `0`s) in the bitmap is time-consuming, making the system inefficient.


### Linked List for Dynamic Partitioning

The better and the **most popular approach** to keep track of the free or filled partitions is using Linked List.

In this approach, the **Operating system maintains a linked list where each node represents each partition**. Every **node has three fields**.
1. First field of the node stores a flag bit which shows whether the partition is a hole or some process is inside.
2. Second field stores the starting index of the partition.
3. Third filed stores the end index of the partition.

   ![[os-linked-list-for-dynamic-partitioning.png]]
If a **partition is freed at some point of time then that partition will be merged** with its adjacent free partition without doing any extra effort.

There are some points which need to be focused while using this approach.
1. The OS must be very clear about the location of the new node which is to be added in the linked list. However, adding the node according to the increasing order of starting index is suggestible.
2. **Using a doubly linked list will make some positive effects on the performance** due to the fact that a node in the doubly link list can also keep track of its previous node.


### Partitioning Algorithms
Partitioning algorithms are used in dynamic memory management to decide how to allocate free memory blocks to processes. These algorithms help determine which part of memory should be allocated to a process when it requests memory. The choice of algorithm impacts memory efficiency and how fragmentation is managed. Here are the most common partitioning algorithms:

##### 1. **First-Fit Algorithm**

- **How it works**: The OS scans the memory from the beginning and assigns the first available block of memory that is large enough to satisfy the process's request.
  
- **Steps**:
    1. Start scanning from the beginning of the free list.
    2. Assign the first free block that is equal to or larger than the requested memory.
    3. If the block is larger, it splits the block and uses the first part for the process, leaving the remaining part as free memory.
       
- **Advantages**:
    - Simple and fast to implement because it allocates memory as soon as it finds the first suitable block.
    - Works well in situations where memory requests are small and frequent.
      
- **Disadvantages**:
    - Can lead to **external fragmentation** (small free spaces scattered across memory).
    - It may not utilize memory efficiently, as small gaps are left behind after allocation.


##### 2. **Next-Fit Algorithm**

- **How it works**: Similar to **first-fit**, but instead of always starting the search from the beginning of the free list, the OS resumes the search from where the last allocation was made. This avoids repeatedly scanning the same memory regions.
  
- **Steps**:
    1. Start scanning from the location of the last allocation.
    2. Find the next free block that can accommodate the request.
    3. Allocate the block and split it if necessary.
       
- **Advantages**:
    - Slightly faster than first-fit since it doesn’t repeatedly scan from the start.
    - Reduces the likelihood of repeatedly fragmenting the beginning of memory.
      
- **Disadvantages**:
    - Can lead to uneven memory usage as the last part of memory might be allocated more frequently.
    - Like first-fit, it may result in **external fragmentation**.


##### 3. **Best-Fit Algorithm**

- **How it works**: The OS searches the entire memory to find the smallest free block that is large enough to satisfy the process's memory request.
  
- **Steps**:
    1. Search the entire list of free blocks.
    2. Select the block that is closest in size to the memory required by the process.
    3. If the block is larger, it splits the block and uses part of it, leaving the remaining part as free memory.
       
- **Advantages**:
    - Minimizes waste of large memory blocks.
    - Reduces external fragmentation in some cases because it tries to use blocks most efficiently.
      
- **Disadvantages**:
    - Slower than **first-fit** as it scans the entire memory list before allocating memory.
    - May increase **small gaps** (fragments) because the best-fit block leaves the smallest leftover space.


##### 4. **Worst-Fit Algorithm**

- **How it works**: The OS searches the entire memory list and selects the largest available free block for allocation. The idea is that large blocks can handle future memory requests better after splitting.
  
- **Steps**:
    1. Scan the memory for the largest free block.
    2. Allocate the block to the process, splitting it if necessary.
    3. The remaining part becomes free memory.
    
- **Advantages**:
    - By using the largest block, the algorithm leaves behind larger leftover blocks, which could be useful for future memory requests.
      
- **Disadvantages**:
    - It can lead to large memory blocks being broken into smaller, unusable chunks, causing **external fragmentation**.
    - Typically less efficient than first-fit or best-fit because it increases fragmentation.



##### 5. **Quick Fit Algorithm**

- **How it works**: The OS maintains separate lists of commonly requested block sizes. When a process requests memory, the OS quickly allocates memory from the corresponding list. If no block of the requested size is available, it searches the larger blocks or creates a new one.
    
- **Advantages**:    
    - **Fast allocation** for processes requiring commonly used block sizes.
    - Reduces search time by keeping separate lists for different block sizes.
      
- **Disadvantages**:
    - It might lead to more **external fragmentation** if blocks of uncommon sizes are frequently requested.
    - Managing multiple lists can introduce **management overhead**.
