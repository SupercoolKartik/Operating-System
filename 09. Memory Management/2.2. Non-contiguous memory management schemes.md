Non-Contiguous Memory Allocation is a **memory management technique where a process is allowed to occupy different sections of physical memory that are not necessarily contiguous**. This approach helps in better memory utilization and **eliminates external fragmentation**. It **breaks the process into smaller chunks and allocates them** to available memory spaces without requiring the entire process to be stored in one continuous block of memory.


### Benefits of Non-Contiguous Memory Allocation:
1. **No External Fragmentation**:
    - Since memory can be allocated in non-contiguous blocks, there are no large unusable memory gaps (external fragmentation).  
2. **Efficient Memory Utilization**:
    - Free memory can be used more efficiently by allocating smaller chunks to different parts of the process, allowing better use of the available memory.  
3. **Scalability**:
    - Processes can grow dynamically in size by acquiring additional pages or segments without needing to relocate the entire process in memory.

### Drawbacks:
1. **Overhead in Address Translation**:
    - Non-contiguous memory allocation requires complex address translation mechanisms, such as page tables or segment tables, adding overhead to the system.
2. **Internal Fragmentation**:
    - In paging, if the last page of a process is not fully utilized, internal fragmentation occurs within the page.

---
### Common Techniques:
- **Paging**:
    - Divides the memory into fixed-size pages and frames, allowing each process to be allocated frames that need not be contiguous in physical memory.
      (More detailed explanation below)
- **Segmentation**:
    - Divides the memory into variable-sized segments based on the logical division of a program, which are allocated in non-contiguous parts of memory.
      (More detailed explanation below)



## 1. Paging


#### Need for Paging

**Disadvantage of Dynamic Partitioning**: The main disadvantage of Dynamic Partitioning is External fragmentation. Although, this can be removed by Compaction but as we have discussed earlier, the compaction makes the system inefficient. We need to find out a mechanism which can load the processes in the partitions in a more optimal way. Let us discuss a dynamic and flexible mechanism called paging.


Lets consider a process P1 of size 2 MB and the main memory which is divided into three partitions. Out of the three partitions, two partitions are holes of size 1 MB each.

P1 needs 2 MB space in the main memory to be loaded. We have two holes of 1 MB each but they are not contiguous.

Although, there is 2 MB space available in the main memory in the form of those holes but that remains useless until it become contiguous. This is a serious problem to address.

We need to have some kind of mechanism which can store one process at different locations of the memory.

**The Idea behind paging is to divide the process in pages** so that, we can store them in the memory at different holes.

  ![[os-need-for-paging.png]]



#### Paging
**Paging** is a memory management technique used to manage how processes access and utilize memory. It divides the process's memory space and the physical memory (RAM) into fixed-size blocks called **pages** (in the process) and **frames** (in memory). Each page of the process can be stored in any available frame in the memory, eliminating the need for contiguous memory allocation.

###### Key Concepts in Paging:

1. **Pages and Frames**:
    - **Page**: A fixed-size block of data in a processâ€™s memory space.
    - **Frame**: A fixed-size block of physical memory (RAM) where a page can be loaded. Pages and frames are of the same size to simplify management.
      
2. **Page Table**: Each process has its own **page table** that keeps track of where each page of the process is stored in memory. It maps the page number to the corresponding frame in physical memory. This helps the CPU translate logical addresses (used by the process) into physical addresses (used by RAM).
    
3. **Logical Address vs. Physical Address**:
    - **Logical Address**: The address generated by the CPU during a process execution.
    - **Physical Address**: The actual location in the main memory (RAM) where the process's data is stored. The page table helps in converting logical addresses into physical addresses.
      
4. **Paging Mechanism**:
    - When a process is executing, the CPU generates a logical address that needs to be translated to a physical address.
    - The logical address is divided into two parts: **page number** and **page offset**.
    - The **page number** is used to look up the frame number in the page table.
    - The **page offset** is then added to the frame number to get the final physical address.


![[paging-diagram.jpg]]


###### Advantages of Paging
- **No External Fragmentation**: Since pages are of fixed size and can be placed in any available frame, external fragmentation is eliminated.
- **Efficient Use of Memory**: Pages can be stored in any free frame, meaning non-contiguous memory can be utilized effectively.

###### Disadvantages of Paging
 - **Internal Fragmentation**: Since pages are fixed size, if a process does not completely fill a page, the leftover space within the page is wasted.
- **Overhead of Page Table**: Maintaining a page table for each process adds memory overhead, especially for large processes.


##### Page table handling during context switching with paging:

1. **Saving the Current Process's Page Table**
When the operating system decides to switch from one process (let's call it **Process A**) to another (let's call it **Process B**), the **page table** for **Process A** needs to be saved:

- The **page table base register** (often called the **CR3** register in x86 architecture) holds the address of the page table for the currently running process.
- During a context switch, the OS saves the **page table base register** (CR3) of **Process A** along with other CPU state information (like the program counter, general registers, etc.) in **Process A's PCB** (Process Control Block).

2. **Loading the Page Table for the Next Process**
After saving the state of **Process A**, the OS prepares to switch to **Process B**:

- The OS retrieves the **page table base register (CR3)** for **Process B** from **Process B's PCB**.
- This new page table base register now points to **Process B's** page table, which maps **Process B's virtual memory** to its corresponding **physical memory** locations.

3. **Flushing the Translation Lookaside Buffer (TLB)**
Once the page table for **Process B** is loaded, the OS typically **flushes the TLB** (Translation Lookaside Buffer). The TLB is a cache used by the CPU to speed up virtual-to-physical address translations:
- Since each process has its own page table, the **TLB entries for Process A** are now invalid, as they belong to **Process A's** virtual memory space.
- **Flushing the TLB** ensures that the next memory accesses made by **Process B** use **Process B's** page table for translation, rather than stale entries from **Process A**.

4. **Memory Access Using the New Page Table**

After the page table switch, all subsequent memory accesses by **Process B** will use its own **page table** to map virtual addresses to physical memory. The CPU, through the MMU (Memory Management Unit), will use the new page table to handle address translations for **Process B**.