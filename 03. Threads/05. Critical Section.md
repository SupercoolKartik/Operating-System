
In computer science, a **critical section refers to a segment of code that is executed by multiple concurrent threads or processes**, **and which accesses shared resources**. These resources may include shared memory, files, or other system resources that can only be accessed by one thread or process at a time to avoid data inconsistency or race conditions.

**Note:** The critical section cannot be executed by more than one process at the same time; operating system faces the difficulties in allowing and disallowing the processes from entering the critical section.

#### Code containing critical section
![Alt Text](critical-section.png)


## Race Condition
A race condition occurs when multiple processes or threads access shared resources concurrently, leading to inconsistent or incorrect results. Proper synchronization mechanisms must be in place to avoid race conditions.

In concurrent programming, if one thread tries to change the value of shared data at the same time as another thread tries to read the value (i.e., data race across threads), the result is unpredictable. The access to such shared variables (shared memory, shared files, shared port, etc.) is to be synchronized.


## Components of the Critical Section Problem

1. **Entry Section:** The code that requests entry to the critical section. The process or thread must acquire a lock or some form of permission before entering the critical section.

2. **Critical Section:** The section of code where the shared resource is accessed. Only one process or thread is allowed to execute this section at a time.

3. **Exit Section:** The code that runs after the critical section, releasing the lock or permission, allowing other processes or threads to enter the critical section.

4. **Remainder Section:** The rest of the code outside the critical section that does not involve accessing the shared resource.




## Requirements of Synchronization mechanisms

##### Primary

1. **Mutual Exclusion**: Our solution must provide mutual exclusion. By Mutual Exclusion, we mean that if one process is executing inside critical section then the other process must not enter in the critical section.

2. **Progress**: Progress means that if one process doesn't need to execute into critical section then it should not stop other processes to get into the critical section.
   [[Progress | more.]]

##### Secondary

1. **Bounded Waiting**: We should be able to predict the waiting time for every process to get into the critical section. The process must not be endlessly waiting for getting into the critical section.

3. **Architectural Neutrality (Portability)**: Our mechanism must be architectural natural. It means that if our solution is working fine on one architecture then it should also run on the other ones as well.



## Lock Variable

This is the simplest synchronization mechanism. This is a Software Mechanism implemented in User mode. This is a busy waiting solution which can be used for more than two processes.

In this mechanism, a Lock variable **lock** is used. Two values of lock can be possible, either 0 or 1. Lock value 0 means that the critical section is vacant while the lock value 1 means that it is occupied.

A process which wants to get into the critical section first checks the value of the lock variable. If it is 0 then it sets the value of lock as 1 and enters into the critical section, otherwise it waits.

The pseudo code of the mechanism looks like following. 
```
Entry Section →   
While (lock! = 0);   
Lock = 1;  
//Critical Section   
Exit Section →  
Lock =0;
```

If we look at the Pseudo Code, we find that there are three sections in the code. Entry Section, Critical Section and the exit section.

Initially the value of **lock variable** is **0**. The process which needs to get into the **critical section**, enters into the entry section and checks the condition provided in the while loop.

The process will wait infinitely until the value of **lock** is 1 (that is implied by while loop). Since, at the very first time critical section is vacant hence the process will enter the critical section by setting the lock variable as 1.

When the process exits from the critical section, then in the exit section, it reassigns the value of **lock** as 0.



## Peterson's Algorithm

Peterson's solution is a classic **solution to the critical section problem**. Peterson solution provides you all the necessary requirements such as Mutual Exclusion, Progress, Bounded Waiting and Portability. It is **designed for two processes** and is **based on the principle of busy-waiting**.

The algorithm uses two shared variables:

- `flag[2]`: An array where each entry is a Boolean indicating if a process wants to enter the critical section.
- `turn`: An integer variable that indicates whose turn it is to enter the critical section.

###### Algorithm
Assume we have two processes, P0 and P1.

**Initialization:**
```
boolean flag[2] = {false, false}; // Both processes initially do not want to enter critical section
int turn = 0;                     // Turn can be set to either process initially
```

**Process P0:**
```
// Entry Section
flag[0] = true;     // P0 wants to enter critical section
turn = 1;           // Set turn to P1 (It won't enter into the CS but allow the                        other process for it)
while (flag[1] && turn == 1) {
    // Busy-wait (Here it will check flag[1] i.e. if other process is also            ready to enter the CS, if not, then flag[1] will be false and this              process will move forward, but if other process also wants to enter then        flag[1] will be true making the while loop conditions to be true and it         won't go forward to the loop)
}                 

// Critical Section
// [Critical section code goes here]

// Exit Section
flag[0] = false;    // P0 leaves the critical section
```

**Process P1:**
```
// Entry Section
flag[1] = true;     // P1 wants to enter critical section (Now P1 also wants to                        to enter the Critical section along with P0, it will                            also give turn to anothor process)
turn = 0;           // Set turn to P0 (Now the since the turn if set to 0, the                         while loop in the previous process ends and will go                             forward)
while (flag[0] && turn == 0) {
    // Busy-wait (This loop will continue untill P0 conpletes the CS and go to        the Remainder Section and set flag[0] to false which will break this            while loop and make this P1 enter the CS eventually too)
}

// Critical Section
// [Critical section code goes here]

// Exit Section
flag[1] = false;    // P1 leaves the critical section
```

###### Explanation

1. **Entry Section:**
    - Each process indicates its intention to enter the critical section by setting its corresponding `flag` to `true`.
    - The `turn` variable is set to the other process, giving the other process the priority to enter the critical section.
    
1. **Busy-Waiting Loop:**
    - The process then enters a while loop that continues to execute as long as the other process wants to enter the critical section (`flag[other] == true`) and it is the other process's turn (`turn == other`).
    
1. **Critical Section:**
    - Once the while loop condition is false, the process enters the critical section and executes the critical code.
    
1. **Exit Section:**
    - After executing the critical section, the process resets its `flag` to `false`, indicating that it no longer needs the critical section.


###### Advantages of Peterson's Algorithm
1. **Simplicity:** The algorithm is simple and easy to understand.
2. **Mutual Exclusion:** Ensures that only one process can enter the critical section at a time.
3. **No Hardware Support:** Does not require any special hardware instructions, making it suitable for simple systems.
4. **Fairness:** The algorithm ensures fairness, preventing starvation as each process gets a fair chance to enter the critical section.


###### Disadvantages of Peterson's Algorithm
1. **Two-Process Limitation:** The basic form of the algorithm is limited to only two processes. Extending it to more processes is complex and inefficient.
2. **Busy-Waiting:** The algorithm relies on busy-waiting, which can lead to CPU time wastage.
3. **Non-scalability:** As the number of processes increases, the algorithm becomes less efficient and harder to implement.